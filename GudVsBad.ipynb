{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying Cats vs Dogs with a Convolutional Neural Network on Kaggle3\n",
    "\n",
    "# Below model from: https://pythonprogramming.net/convolutional-neural-network-kats-vs-dogs-machine-learning-tutorial/\n",
    "# Import all libraries as below\n",
    "# install OpenCV for first time\n",
    "\n",
    "# Full run through of raw images to classification with Convolutional Neural Network : Dogs Vs Cats\n",
    "# Package Requirements\n",
    "#numpy (pip install numpy) tqdm (pip install tqdm)\n",
    "#I will be using the GPU version of TensorFlow along with tflearn.\n",
    "\n",
    "#To install the CPU version of TensorFlow, just do pip install tensorflow To install the GPU version of TensorFlow, \n",
    "# you need to get all the dependencies and such.\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os \n",
    "from random import shuffle\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\IIM\\\\TensorFlow\\\\warranty\\\\Bearings'"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy test and train datasets from Kaggle into the local PC and provide the pat of Test and Train Directories as below\n",
    "\n",
    "#Once you have downloaded and extracted the data from https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data, \n",
    "# you're ready to begin.\n",
    "\n",
    "# We've got the data, but we can't exactly just stuff raw images right through our convolutional neural network. \n",
    "# First, we need all of the images to be the same size, and then we also will probably want to just grayscale them. \n",
    "# Also, the labels of \"gud\" and \"bad\" are not useful, we want them to be one-hot arrays.\n",
    "\n",
    "# TensorFlow Fold makes it easy to implement deep-learning models that operate over data of varying size and structure.\"\n",
    "\n",
    "# Fascinating...but, for now, we'll do it the old fashioned way.\n",
    "\n",
    "#TEST_DIR = \"E:/IIM/TensorFlow/test\"\n",
    "#TRAIN_DIR = \"E:/IIM/TensorFlow/train\"\n",
    "\n",
    "import os\n",
    "os.chdir('E:/IIM/TensorFlow/warranty/Bearings')\n",
    "\n",
    "TEST_DIR = \"E:/IIM/TensorFlow/warranty/Bearings/test\"\n",
    "TRAIN_DIR = \"E:/IIM/TensorFlow/warranty/Bearings/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 50\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'gudVSbad9-{}-{}.model'.format(LR, '2conv-basic')\n",
    "# just so we remember which saved model is which, sizes must match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(img):\n",
    "    word_label = img.split('.')[-3]\n",
    "    # conversion to one-hot array [gud,bad]\n",
    "    #                            [much gud, no bad]\n",
    "    if word_label == 'gud': return [1,0]\n",
    "    #                             [no gud, very bad]\n",
    "    elif word_label == 'bad': return [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(TRAIN_DIR,img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        training_data.append([np.array(img),np.array(label)])\n",
    "    shuffle(training_data)\n",
    "    np.save('train_data.npy', training_data)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data():\n",
    "    testing_data = []\n",
    "    for img in tqdm(os.listdir(TEST_DIR)):\n",
    "        path = os.path.join(TEST_DIR,img)\n",
    "        img_num = img.split('.')[0]\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "        testing_data.append([np.array(img), img_num])\n",
    "        \n",
    "    shuffle(testing_data)\n",
    "    np.save('test_data.npy', testing_data)\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 64.89it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = create_train_data()\n",
    "# If you have already created the dataset:\n",
    "#train_data = np.load('train_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next, we're ready to define our neural network:\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflearn.data_preprocessing import ImagePreprocessing\n",
    "from tflearn.data_augmentation import ImageAugmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalisation of images\n",
    "img_prep = ImagePreprocessing()\n",
    "img_prep.add_featurewise_zero_center()\n",
    "img_prep.add_featurewise_stdnorm()\n",
    "\n",
    "# Create extra synthetic training data by flipping & rotating images\n",
    "img_aug = ImageAugmentation()\n",
    "img_aug.add_random_flip_leftright()\n",
    "img_aug.add_random_rotation(max_angle=25.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input',data_preprocessing=img_prep, data_augmentation=img_aug)\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = tflearn.DNN(convnet, tensorboard_dir='log')\n",
    "#What we have here is a nice, 2 layered convolutional neural network, with a fully connected layer, \n",
    "# and then the output layer. It's been debated whether or not a fully connected layer is of any use. \n",
    "# I'll leave it in anyway. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This exact convnet was good enough for recognizing hand 28x28 written digits. \n",
    "# Let's see how it does with gud and bad bearings at 50x50 resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, it wont always be the case that you're training the network fresh every time. \n",
    "# Maybe first you just want to see how 3 epochs trains, but then, after 3, maybe you're done, \n",
    "# or maybe you want to see about 5 epochs. We want to be saving our model after every session, and reloading it\n",
    "# if we have a saved version, so I will add this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('{}.meta'.format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print('model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, let's split out training and testing data:\n",
    "\n",
    "train = train_data[:-1]\n",
    "test = train_data[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the training data and testing data are both labeled datasets. The training data is what we'll fit the neural network with, and the test data is what we're going to use to validate the results. The test data will be \"out of sample,\" meaning the testing data will only be used to test the accuracy of the network, not to train it.\n",
    "\n",
    "We also have \"test\" images that we downloaded. THOSE images are not labeled at all, and those are what we'll submit to Kaggle for the competition.\n",
    "\n",
    "Next, we're going to create our data arrays. For some reason, typical numpy logic like:\n",
    "\n",
    "array[:,0] and array[:,1] did NOT work for me here. Not sure what I'm doing wrong, so I do this instead to separate my features and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "Y = [i[1] for i in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "test_y = [i[1] for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: gudVSbad9-0.001-2conv-basic.model\n",
      "Log directory: log/\n",
      "INFO:tensorflow:Summary name Accuracy/ (raw) is illegal; using Accuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 20\n",
      "Validation samples: 5\n",
      "--\n",
      "Training Step: 1  | time: 1.377s\n",
      "| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 2  | total loss: 6.33635 | time: 1.050s\n",
      "| Adam | epoch: 002 | loss: 6.33635 - acc: 0.4050 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 3  | total loss: 9.62976 | time: 1.055s\n",
      "| Adam | epoch: 003 | loss: 9.62976 - acc: 0.5236 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 4  | total loss: 10.17867 | time: 1.063s\n",
      "| Adam | epoch: 004 | loss: 10.17867 - acc: 0.5434 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 5  | total loss: 10.30534 | time: 1.096s\n",
      "| Adam | epoch: 005 | loss: 10.30534 - acc: 0.5480 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 6  | total loss: 10.34153 | time: 1.057s\n",
      "| Adam | epoch: 006 | loss: 10.34153 - acc: 0.5493 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 7  | total loss: 10.35359 | time: 1.064s\n",
      "| Adam | epoch: 007 | loss: 10.35359 - acc: 0.5497 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 8  | total loss: 10.35811 | time: 1.050s\n",
      "| Adam | epoch: 008 | loss: 10.35811 - acc: 0.5499 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 9  | total loss: 10.35998 | time: 1.069s\n",
      "| Adam | epoch: 009 | loss: 10.35998 - acc: 0.5499 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 10  | total loss: 10.36081 | time: 1.047s\n",
      "| Adam | epoch: 010 | loss: 10.36081 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 11  | total loss: 10.36120 | time: 1.063s\n",
      "| Adam | epoch: 011 | loss: 10.36120 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 12  | total loss: 10.36139 | time: 1.044s\n",
      "| Adam | epoch: 012 | loss: 10.36139 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 13  | total loss: 10.36150 | time: 1.052s\n",
      "| Adam | epoch: 013 | loss: 10.36150 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 14  | total loss: 10.36155 | time: 1.051s\n",
      "| Adam | epoch: 014 | loss: 10.36155 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 15  | total loss: 10.36158 | time: 1.047s\n",
      "| Adam | epoch: 015 | loss: 10.36158 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 16  | total loss: 10.36160 | time: 1.045s\n",
      "| Adam | epoch: 016 | loss: 10.36160 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 17  | total loss: 10.36161 | time: 1.052s\n",
      "| Adam | epoch: 017 | loss: 10.36161 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 18  | total loss: 10.36162 | time: 1.046s\n",
      "| Adam | epoch: 018 | loss: 10.36162 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 19  | total loss: 10.36162 | time: 1.062s\n",
      "| Adam | epoch: 019 | loss: 10.36162 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 20  | total loss: 10.36163 | time: 1.046s\n",
      "| Adam | epoch: 020 | loss: 10.36163 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 21  | total loss: 10.36163 | time: 1.046s\n",
      "| Adam | epoch: 021 | loss: 10.36163 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 22  | total loss: 10.36163 | time: 1.049s\n",
      "| Adam | epoch: 022 | loss: 10.36163 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 23  | total loss: 10.36163 | time: 1.048s\n",
      "| Adam | epoch: 023 | loss: 10.36163 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 24  | total loss: 10.36163 | time: 1.052s\n",
      "| Adam | epoch: 024 | loss: 10.36163 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 25  | total loss: 10.36163 | time: 1.066s\n",
      "| Adam | epoch: 025 | loss: 10.36163 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 26  | total loss: 10.36163 | time: 1.048s\n",
      "| Adam | epoch: 026 | loss: 10.36163 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 27  | total loss: 10.36163 | time: 1.045s\n",
      "| Adam | epoch: 027 | loss: 10.36163 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 28  | total loss: 10.36163 | time: 1.061s\n",
      "| Adam | epoch: 028 | loss: 10.36163 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 29  | total loss: 10.36163 | time: 1.068s\n",
      "| Adam | epoch: 029 | loss: 10.36163 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 30  | total loss: 10.36163 | time: 1.064s\n",
      "| Adam | epoch: 030 | loss: 10.36163 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 31  | total loss: 10.36163 | time: 1.051s\n",
      "| Adam | epoch: 031 | loss: 10.36163 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 32  | total loss: 10.36163 | time: 1.049s\n",
      "| Adam | epoch: 032 | loss: 10.36163 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 33  | total loss: 10.36163 | time: 1.066s\n",
      "| Adam | epoch: 033 | loss: 10.36163 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 34  | total loss: 10.36163 | time: 1.064s\n",
      "| Adam | epoch: 034 | loss: 10.36163 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 35  | total loss: 10.36163 | time: 1.063s\n",
      "| Adam | epoch: 035 | loss: 10.36163 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 36  | total loss: 10.36163 | time: 1.073s\n",
      "| Adam | epoch: 036 | loss: 10.36163 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 37  | total loss: 10.36163 | time: 1.058s\n",
      "| Adam | epoch: 037 | loss: 10.36163 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 38  | total loss: 10.36163 | time: 1.063s\n",
      "| Adam | epoch: 038 | loss: 10.36163 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 39  | total loss: 10.36163 | time: 1.060s\n",
      "| Adam | epoch: 039 | loss: 10.36163 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 40  | total loss: 10.36163 | time: 1.069s\n",
      "| Adam | epoch: 040 | loss: 10.36163 - acc: 0.5500 | val_loss: 0.00000 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Now we fit for 3 epochs:\n",
    "\n",
    "model.fit({'input': X}, {'targets': Y}, n_epoch=40, validation_set=({'input': test_x}, {'targets': test_y}), \n",
    "    snapshot_step=500, show_metric=True, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Step: 1148  | total loss: 11.40617 | time: 59.952s\n",
    "#| Adam | epoch: 003 | loss: 11.40617 - acc: 0.5046 -- iter: 24448/24500\n",
    "#Training Step: 1149  | total loss: 11.12902 | time: 61.102s\n",
    "#| Adam | epoch: 003 | loss: 11.12902 - acc: 0.5167 | val_loss: 11.60503 - val_acc: 0.4960 -- iter: 24500/24500\n",
    "#--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It doesn't look like we've gotten anywhere at all.\n",
    "\n",
    "#We could keep trying, but, if you haven't made accuracy progress in the first 3 epochs, you're probably not going to at all, \n",
    "#unless it's due to overfitment...at least in my experience.\n",
    "\n",
    "#So... now what?\n",
    "#  Size Matters¶\n",
    "#We're gonna need a bigger network\n",
    "\n",
    "#First, we need to reset the graph instance, since we're doing this in a continuous environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('{}.meta'.format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print('model loaded!')\n",
    "\n",
    "train = train_data[:-1]\n",
    "test = train_data[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "Y = [i[1] for i in train]\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "test_y = [i[1] for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: gudVSbad9-0.001-2conv-basic.model\n",
      "Log directory: log/\n",
      "INFO:tensorflow:Summary name Accuracy/ (raw) is illegal; using Accuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 20\n",
      "Validation samples: 5\n",
      "--\n",
      "Training Step: 1  | time: 1.465s\n",
      "| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 | val_loss: 0.46331 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 2  | total loss: 0.62300 | time: 1.065s\n",
      "| Adam | epoch: 002 | loss: 0.62300 - acc: 0.5850 | val_loss: 0.58425 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 3  | total loss: 0.68257 | time: 1.063s\n",
      "| Adam | epoch: 003 | loss: 0.68257 - acc: 0.5564 | val_loss: 0.66209 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 4  | total loss: 0.68572 | time: 1.056s\n",
      "| Adam | epoch: 004 | loss: 0.68572 - acc: 0.5516 | val_loss: 0.63420 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 5  | total loss: 0.68476 | time: 1.055s\n",
      "| Adam | epoch: 005 | loss: 0.68476 - acc: 0.5851 | val_loss: 0.53560 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 6  | total loss: 0.68990 | time: 1.053s\n",
      "| Adam | epoch: 006 | loss: 0.68990 - acc: 0.5625 | val_loss: 0.46177 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 7  | total loss: 0.68144 | time: 1.052s\n",
      "| Adam | epoch: 007 | loss: 0.68144 - acc: 0.5550 | val_loss: 0.54171 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 8  | total loss: 0.69227 | time: 1.064s\n",
      "| Adam | epoch: 008 | loss: 0.69227 - acc: 0.5522 | val_loss: 0.57469 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 9  | total loss: 0.67502 | time: 1.069s\n",
      "| Adam | epoch: 009 | loss: 0.67502 - acc: 0.5510 | val_loss: 0.50260 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 10  | total loss: 0.67008 | time: 1.049s\n",
      "| Adam | epoch: 010 | loss: 0.67008 - acc: 0.5505 | val_loss: 0.58638 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 11  | total loss: 0.69446 | time: 1.054s\n",
      "| Adam | epoch: 011 | loss: 0.69446 - acc: 0.5266 | val_loss: 0.54010 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 12  | total loss: 0.67800 | time: 1.048s\n",
      "| Adam | epoch: 012 | loss: 0.67800 - acc: 0.6046 | val_loss: 0.45006 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 13  | total loss: 0.66013 | time: 1.051s\n",
      "| Adam | epoch: 013 | loss: 0.66013 - acc: 0.6026 | val_loss: 0.43884 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 14  | total loss: 0.65294 | time: 1.054s\n",
      "| Adam | epoch: 014 | loss: 0.65294 - acc: 0.6016 | val_loss: 0.42699 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 15  | total loss: 0.62924 | time: 1.048s\n",
      "| Adam | epoch: 015 | loss: 0.62924 - acc: 0.6401 | val_loss: 0.22618 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 16  | total loss: 0.60164 | time: 1.057s\n",
      "| Adam | epoch: 016 | loss: 0.60164 - acc: 0.6813 | val_loss: 0.49352 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 17  | total loss: 0.73301 | time: 1.057s\n",
      "| Adam | epoch: 017 | loss: 0.73301 - acc: 0.5800 | val_loss: 0.33037 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 18  | total loss: 0.66059 | time: 1.064s\n",
      "| Adam | epoch: 018 | loss: 0.66059 - acc: 0.7081 | val_loss: 0.23575 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 19  | total loss: 0.59434 | time: 1.063s\n",
      "| Adam | epoch: 019 | loss: 0.59434 - acc: 0.7387 | val_loss: 0.51220 - val_acc: 0.6000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 20  | total loss: 0.53850 | time: 1.072s\n",
      "| Adam | epoch: 020 | loss: 0.53850 - acc: 0.7745 | val_loss: 1.18103 - val_acc: 0.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 21  | total loss: 0.66440 | time: 1.054s\n",
      "| Adam | epoch: 021 | loss: 0.66440 - acc: 0.6583 | val_loss: 0.80274 - val_acc: 0.4000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 22  | total loss: 0.69696 | time: 1.044s\n",
      "| Adam | epoch: 022 | loss: 0.69696 - acc: 0.6108 | val_loss: 0.19920 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 23  | total loss: 0.66705 | time: 1.055s\n",
      "| Adam | epoch: 023 | loss: 0.66705 - acc: 0.6222 | val_loss: 0.06326 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 24  | total loss: 0.58346 | time: 1.054s\n",
      "| Adam | epoch: 024 | loss: 0.58346 - acc: 0.6863 | val_loss: 0.07047 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 25  | total loss: 0.56650 | time: 1.061s\n",
      "| Adam | epoch: 025 | loss: 0.56650 - acc: 0.6900 | val_loss: 0.23300 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 26  | total loss: 0.52513 | time: 1.065s\n",
      "| Adam | epoch: 026 | loss: 0.52513 - acc: 0.7059 | val_loss: 0.90734 - val_acc: 0.2000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 27  | total loss: 0.59703 | time: 1.055s\n",
      "| Adam | epoch: 027 | loss: 0.59703 - acc: 0.6529 | val_loss: 1.01270 - val_acc: 0.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 28  | total loss: 0.64385 | time: 1.073s\n",
      "| Adam | epoch: 028 | loss: 0.64385 - acc: 0.6022 | val_loss: 0.84641 - val_acc: 0.2000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 29  | total loss: 0.66744 | time: 1.075s\n",
      "| Adam | epoch: 029 | loss: 0.66744 - acc: 0.5652 | val_loss: 0.63150 - val_acc: 0.6000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 30  | total loss: 0.67179 | time: 1.070s\n",
      "| Adam | epoch: 030 | loss: 0.67179 - acc: 0.5497 | val_loss: 0.41403 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 31  | total loss: 0.65264 | time: 1.064s\n",
      "| Adam | epoch: 031 | loss: 0.65264 - acc: 0.6075 | val_loss: 0.25767 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 32  | total loss: 0.62370 | time: 1.046s\n",
      "| Adam | epoch: 032 | loss: 0.62370 - acc: 0.6621 | val_loss: 0.17426 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 33  | total loss: 0.59983 | time: 1.064s\n",
      "| Adam | epoch: 033 | loss: 0.59983 - acc: 0.6375 | val_loss: 0.15922 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 34  | total loss: 0.58095 | time: 1.056s\n",
      "| Adam | epoch: 034 | loss: 0.58095 - acc: 0.6187 | val_loss: 0.18966 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 35  | total loss: 0.55474 | time: 1.064s\n",
      "| Adam | epoch: 035 | loss: 0.55474 - acc: 0.6253 | val_loss: 0.22440 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 36  | total loss: 0.52148 | time: 1.065s\n",
      "| Adam | epoch: 036 | loss: 0.52148 - acc: 0.6712 | val_loss: 0.18462 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 37  | total loss: 0.48356 | time: 1.062s\n",
      "| Adam | epoch: 037 | loss: 0.48356 - acc: 0.7370 | val_loss: 0.10189 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 38  | total loss: 0.44168 | time: 1.074s\n",
      "| Adam | epoch: 038 | loss: 0.44168 - acc: 0.7884 | val_loss: 0.06994 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 39  | total loss: 0.39784 | time: 1.074s\n",
      "| Adam | epoch: 039 | loss: 0.39784 - acc: 0.8194 | val_loss: 0.09800 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 40  | total loss: 0.35136 | time: 1.052s\n",
      "| Adam | epoch: 040 | loss: 0.35136 - acc: 0.8532 | val_loss: 0.07693 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 41  | total loss: 0.30202 | time: 1.076s\n",
      "| Adam | epoch: 041 | loss: 0.30202 - acc: 0.8802 | val_loss: 0.24847 - val_acc: 0.8000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 42  | total loss: 0.68616 | time: 1.055s\n",
      "| Adam | epoch: 042 | loss: 0.68616 - acc: 0.8118 | val_loss: 0.03533 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 43  | total loss: 0.58538 | time: 1.060s\n",
      "| Adam | epoch: 043 | loss: 0.58538 - acc: 0.8362 | val_loss: 0.04925 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "model.fit({'input': X}, {'targets': Y}, n_epoch=43, validation_set=({'input': test_x}, {'targets': test_y}), \n",
    "    snapshot_step=500, show_metric=True, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Step: 1148  | total loss: 0.46025 | time: 63.884s\n",
    "#| Adam | epoch: 003 | loss: 0.46025 - acc: 0.7903 -- iter: 24448/24500\n",
    "#Training Step: 1149  | total loss: 0.45743 | time: 65.061s\n",
    "#| Adam | epoch: 003 | loss: 0.45743 - acc: 0.7925 | val_loss: 0.50954 - val_acc: 0.7200 -- iter: 24500/24500\n",
    "#--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WELL WELL WELL... Looks like we've got a winner. With neural networks, size matters a ton. We went from having apparently \n",
    "# un-trainable data to having obviously trainable data, and this was only 3 epochs.\n",
    "\n",
    "#If you are happy with the model, go ahead and save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:E:\\IIM\\TensorFlow\\warranty\\Bearings\\gudVSbad9-0.001-2conv-basic.model is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model.save(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFO:tensorflow:C:\\Users\\Eshwar\\dogsvscats-0.001-2conv-basic.model is not in all_model_checkpoint_paths. Manually adding it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can reload the model, and continue training (we don't NEED to reload the model here since this is continuous \n",
    "# and the model is still in memory, but if you were running this as a program you would)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tflearn.DNN(convnet, tensorboard_dir='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: gudVSbad9-0.001-2conv-basic.model\n",
      "Log directory: log/\n",
      "INFO:tensorflow:Summary name Accuracy/ (raw) is illegal; using Accuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 20\n",
      "Validation samples: 5\n",
      "--\n",
      "Training Step: 1  | time: 1.463s\n",
      "| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 | val_loss: 0.42677 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 2  | total loss: 0.61975 | time: 1.070s\n",
      "| Adam | epoch: 002 | loss: 0.61975 - acc: 0.5400 | val_loss: 0.61284 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 3  | total loss: 0.67860 | time: 1.064s\n",
      "| Adam | epoch: 003 | loss: 0.67860 - acc: 0.5482 | val_loss: 0.63047 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 4  | total loss: 0.68125 | time: 1.063s\n",
      "| Adam | epoch: 004 | loss: 0.68125 - acc: 0.5495 | val_loss: 0.58383 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 5  | total loss: 0.68481 | time: 1.066s\n",
      "| Adam | epoch: 005 | loss: 0.68481 - acc: 0.5499 | val_loss: 0.58178 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 6  | total loss: 0.69166 | time: 1.066s\n",
      "| Adam | epoch: 006 | loss: 0.69166 - acc: 0.5500 | val_loss: 0.54520 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 7  | total loss: 0.68110 | time: 1.057s\n",
      "| Adam | epoch: 007 | loss: 0.68110 - acc: 0.5500 | val_loss: 0.55674 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 8  | total loss: 0.67938 | time: 1.076s\n",
      "| Adam | epoch: 008 | loss: 0.67938 - acc: 0.5500 | val_loss: 0.43559 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 9  | total loss: 0.66191 | time: 1.062s\n",
      "| Adam | epoch: 009 | loss: 0.66191 - acc: 0.5765 | val_loss: 0.54857 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 10  | total loss: 0.67965 | time: 1.061s\n",
      "| Adam | epoch: 010 | loss: 0.67965 - acc: 0.5632 | val_loss: 0.45699 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 11  | total loss: 0.65371 | time: 1.067s\n",
      "| Adam | epoch: 011 | loss: 0.65371 - acc: 0.6517 | val_loss: 0.32102 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 12  | total loss: 0.62694 | time: 1.068s\n",
      "| Adam | epoch: 012 | loss: 0.62694 - acc: 0.6959 | val_loss: 0.52360 - val_acc: 0.8000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 13  | total loss: 0.65519 | time: 1.074s\n",
      "| Adam | epoch: 013 | loss: 0.65519 - acc: 0.6334 | val_loss: 0.26013 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 14  | total loss: 0.60375 | time: 1.065s\n",
      "| Adam | epoch: 014 | loss: 0.60375 - acc: 0.7425 | val_loss: 0.28029 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 15  | total loss: 0.55612 | time: 1.069s\n",
      "| Adam | epoch: 015 | loss: 0.55612 - acc: 0.7454 | val_loss: 0.82627 - val_acc: 0.4000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 16  | total loss: 0.71168 | time: 1.062s\n",
      "| Adam | epoch: 016 | loss: 0.71168 - acc: 0.5596 | val_loss: 0.76489 - val_acc: 0.4000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 17  | total loss: 0.66843 | time: 1.059s\n",
      "| Adam | epoch: 017 | loss: 0.66843 - acc: 0.5922 | val_loss: 0.37587 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 18  | total loss: 0.69726 | time: 1.069s\n",
      "| Adam | epoch: 018 | loss: 0.69726 - acc: 0.5603 | val_loss: 0.12776 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 19  | total loss: 0.60470 | time: 1.074s\n",
      "| Adam | epoch: 019 | loss: 0.60470 - acc: 0.7068 | val_loss: 0.11876 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 20  | total loss: 0.67833 | time: 1.053s\n",
      "| Adam | epoch: 020 | loss: 0.67833 - acc: 0.6564 | val_loss: 0.18333 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 21  | total loss: 0.63703 | time: 1.080s\n",
      "| Adam | epoch: 021 | loss: 0.63703 - acc: 0.6389 | val_loss: 0.33824 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 22  | total loss: 0.57545 | time: 1.076s\n",
      "| Adam | epoch: 022 | loss: 0.57545 - acc: 0.6722 | val_loss: 0.40491 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 23  | total loss: 0.52986 | time: 1.077s\n",
      "| Adam | epoch: 023 | loss: 0.52986 - acc: 0.7674 | val_loss: 0.27210 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 24  | total loss: 0.50246 | time: 1.101s\n",
      "| Adam | epoch: 024 | loss: 0.50246 - acc: 0.8188 | val_loss: 0.11948 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 25  | total loss: 0.45897 | time: 1.076s\n",
      "| Adam | epoch: 025 | loss: 0.45897 - acc: 0.8682 | val_loss: 0.06542 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 26  | total loss: 0.41419 | time: 1.062s\n",
      "| Adam | epoch: 026 | loss: 0.41419 - acc: 0.8898 | val_loss: 0.05981 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 27  | total loss: 0.57691 | time: 1.081s\n",
      "| Adam | epoch: 027 | loss: 0.57691 - acc: 0.8025 | val_loss: 0.09081 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 28  | total loss: 0.72603 | time: 1.048s\n",
      "| Adam | epoch: 028 | loss: 0.72603 - acc: 0.7268 | val_loss: 0.18833 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 29  | total loss: 0.63275 | time: 1.066s\n",
      "| Adam | epoch: 029 | loss: 0.63275 - acc: 0.7446 | val_loss: 0.39864 - val_acc: 0.8000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 30  | total loss: 0.54171 | time: 1.074s\n",
      "| Adam | epoch: 030 | loss: 0.54171 - acc: 0.8051 | val_loss: 0.74661 - val_acc: 0.4000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 31  | total loss: 0.61526 | time: 1.066s\n",
      "| Adam | epoch: 031 | loss: 0.61526 - acc: 0.7462 | val_loss: 0.69392 - val_acc: 0.6000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 32  | total loss: 0.62645 | time: 1.063s\n",
      "| Adam | epoch: 032 | loss: 0.62645 - acc: 0.7246 | val_loss: 0.45539 - val_acc: 0.8000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 33  | total loss: 0.59581 | time: 1.056s\n",
      "| Adam | epoch: 033 | loss: 0.59581 - acc: 0.7411 | val_loss: 0.36580 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 34  | total loss: 0.66675 | time: 1.071s\n",
      "| Adam | epoch: 034 | loss: 0.66675 - acc: 0.6788 | val_loss: 0.29840 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 35  | total loss: 0.60247 | time: 1.060s\n",
      "| Adam | epoch: 035 | loss: 0.60247 - acc: 0.7460 | val_loss: 0.25432 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 36  | total loss: 0.56036 | time: 1.070s\n",
      "| Adam | epoch: 036 | loss: 0.56036 - acc: 0.7979 | val_loss: 0.23109 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 37  | total loss: 0.52958 | time: 1.069s\n",
      "| Adam | epoch: 037 | loss: 0.52958 - acc: 0.8184 | val_loss: 0.24616 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 38  | total loss: 0.59711 | time: 1.070s\n",
      "| Adam | epoch: 038 | loss: 0.59711 - acc: 0.7365 | val_loss: 0.26325 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 39  | total loss: 0.55375 | time: 1.058s\n",
      "| Adam | epoch: 039 | loss: 0.55375 - acc: 0.7870 | val_loss: 0.33677 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 40  | total loss: 0.61209 | time: 1.077s\n",
      "| Adam | epoch: 040 | loss: 0.61209 - acc: 0.7332 | val_loss: 0.37452 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 41  | total loss: 0.56745 | time: 1.079s\n",
      "| Adam | epoch: 041 | loss: 0.56745 - acc: 0.7822 | val_loss: 0.36050 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 42  | total loss: 0.53374 | time: 1.052s\n",
      "| Adam | epoch: 042 | loss: 0.53374 - acc: 0.8214 | val_loss: 0.29414 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 43  | total loss: 0.50451 | time: 1.073s\n",
      "| Adam | epoch: 043 | loss: 0.50451 - acc: 0.8529 | val_loss: 0.20560 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 44  | total loss: 0.47148 | time: 1.066s\n",
      "| Adam | epoch: 044 | loss: 0.47148 - acc: 0.8784 | val_loss: 0.12629 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 45  | total loss: 0.43389 | time: 1.066s\n",
      "| Adam | epoch: 045 | loss: 0.43389 - acc: 0.8990 | val_loss: 0.11922 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 46  | total loss: 0.49793 | time: 1.068s\n",
      "| Adam | epoch: 046 | loss: 0.49793 - acc: 0.8492 | val_loss: 0.11979 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 47  | total loss: 0.44379 | time: 1.062s\n",
      "| Adam | epoch: 047 | loss: 0.44379 - acc: 0.8739 | val_loss: 0.15881 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 48  | total loss: 0.47403 | time: 1.047s\n",
      "| Adam | epoch: 048 | loss: 0.47403 - acc: 0.8620 | val_loss: 0.15813 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n",
      "Training Step: 49  | total loss: 0.42033 | time: 1.112s\n",
      "| Adam | epoch: 049 | loss: 0.42033 - acc: 0.8838 | val_loss: 0.10554 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 50  | total loss: 0.37303 | time: 1.075s\n",
      "| Adam | epoch: 050 | loss: 0.37303 - acc: 0.9018 | val_loss: 0.05655 - val_acc: 1.0000 -- iter: 20/20\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('C:/Users/Eshwar/{}.meta'.format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print('model loaded!')\n",
    "\n",
    "train = train_data[:-1]\n",
    "test = train_data[-5:]\n",
    "\n",
    "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "Y = [i[1] for i in train]\n",
    "\n",
    "test_x = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "test_y = [i[1] for i in test]\n",
    "\n",
    "model.fit({'input': X}, {'targets': Y}, n_epoch=50, validation_set=({'input': test_x}, {'targets': test_y}), \n",
    "    snapshot_step=500, show_metric=True, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Step: 4978  | total loss: 0.21391 | time: 59.366s\n",
    "#| Adam | epoch: 010 | loss: 0.21391 - acc: 0.9139 -- iter: 24448/24500\n",
    "#Training Step: 4979  | total loss: 0.20713 | time: 60.525s\n",
    "#| Adam | epoch: 010 | loss: 0.20713 - acc: 0.9147 | val_loss: 0.62615 - val_acc: 0.7920 -- iter: 24500/24500\n",
    "#--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can be too big.\n",
    "#Bigger is not always better, there does get to be a limit, at least from my experience.\n",
    "# A bigger network figures things out better, and quicker, but tends to also overfit the training data. \n",
    "# You can use dropout (sets randomly a certain % of nodes to not take part in the network for more robusts networks)\n",
    "# to rectify this slightly, but there does seem to be a limit.\n",
    "\n",
    "# Okay, now what? Let's see how we've done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visually inspecting our network against unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 89.49it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# if you need to create the data:\n",
    "test_data = process_test_data()\n",
    "# if you already have some saved: Yes, saved in below fplder\n",
    "#test_data = np.load('C:/User/Eshwar/test_data.npy')\n",
    "\n",
    "fig=plt.figure()\n",
    "\n",
    "for num,data in enumerate(test_data[:12]):\n",
    "    # gud: [1,0]\n",
    "    # bad: [0,1]\n",
    "    \n",
    "    img_num = data[1]\n",
    "    img_data = data[0]\n",
    "    \n",
    "    y = fig.add_subplot(3,5,num+1)\n",
    "    orig = img_data\n",
    "    data = img_data.reshape(IMG_SIZE,IMG_SIZE,1)\n",
    "    #model_out = model.predict([data])[0]\n",
    "    model_out = model.predict([data])[0]\n",
    "    \n",
    "    if np.argmax(model_out) == 1: str_label='bad'\n",
    "    else: str_label='gud'\n",
    "        \n",
    "    y.imshow(orig,cmap='gray')\n",
    "    plt.title(str_label)\n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, so we made a couple of mistakes, but not too bad actually!\n",
    "\n",
    "If you're happy with it, let's compete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 296.47it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('gudVsbadsubmission_file.csv','w') as f:\n",
    "    f.write('id,label\\n')\n",
    "            \n",
    "with open('gudVsbadsubmission_file.csv','a') as f:\n",
    "    for data in tqdm(test_data):\n",
    "        img_num = data[1]\n",
    "        img_data = data[0]\n",
    "        orig = img_data\n",
    "        data = img_data.reshape(IMG_SIZE,IMG_SIZE,1)\n",
    "        model_out = model.predict([data])[0]\n",
    "        f.write('{},{}\\n'.format(img_num,model_out[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [],
   "source": [
    "#100%|██████████| 8/8 [00:00<00:00, 306.44it/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THE END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\IIM\\\\TensorFlow\\\\warranty\\\\Bearings'"
      ]
     },
     "execution_count": 799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
